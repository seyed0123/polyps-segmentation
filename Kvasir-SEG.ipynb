{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1057e7d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-28T06:13:44.278015Z",
     "iopub.status.busy": "2025-08-28T06:13:44.277691Z",
     "iopub.status.idle": "2025-08-28T06:13:45.730897Z",
     "shell.execute_reply": "2025-08-28T06:13:45.730216Z"
    },
    "papermill": {
     "duration": 1.463306,
     "end_time": "2025-08-28T06:13:45.732466",
     "exception": false,
     "start_time": "2025-08-28T06:13:44.269160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f02df2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T06:13:45.750686Z",
     "iopub.status.busy": "2025-08-28T06:13:45.750306Z",
     "iopub.status.idle": "2025-08-28T06:13:47.555388Z",
     "shell.execute_reply": "2025-08-28T06:13:47.554523Z"
    },
    "papermill": {
     "duration": 1.81595,
     "end_time": "2025-08-28T06:13:47.556982",
     "exception": false,
     "start_time": "2025-08-28T06:13:45.741032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"seaborn\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"scipy\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"albumentations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385e65ba",
   "metadata": {
    "papermill": {
     "duration": 0.006508,
     "end_time": "2025-08-28T06:13:47.570555",
     "exception": false,
     "start_time": "2025-08-28T06:13:47.564047",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602683cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T06:13:47.585940Z",
     "iopub.status.busy": "2025-08-28T06:13:47.585058Z",
     "iopub.status.idle": "2025-08-28T06:13:48.158152Z",
     "shell.execute_reply": "2025-08-28T06:13:48.157449Z"
    },
    "papermill": {
     "duration": 0.581732,
     "end_time": "2025-08-28T06:13:48.159456",
     "exception": false,
     "start_time": "2025-08-28T06:13:47.577724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMAGE_DIR1 = \"/kaggle/input/kvasirseg/Kvasir-SEG/Kvasir-SEG/images\"\n",
    "MASK_DIR1 = \"/kaggle/input/kvasirseg/Kvasir-SEG/Kvasir-SEG/masks\"\n",
    "\n",
    "IMAGE_DIR2 = '/kaggle/input/cvcclinicdb/PNG/Original'\n",
    "MASK_DIR2 = '/kaggle/input/cvcclinicdb/PNG/Ground Truth'\n",
    "\n",
    "IMAGE_DIR3 = '/kaggle/input/merged-polyp-segmentation-datasets/images_valid/images_valid'\n",
    "MASK_DIR3 =  '/kaggle/input/merged-polyp-segmentation-datasets/images_valid/masks_valid'\n",
    "\n",
    "image_paths1 = sorted(glob(os.path.join(IMAGE_DIR1, \"*.jpg\")))\n",
    "mask_paths1 = sorted(glob(os.path.join(MASK_DIR1, \"*.jpg\")))\n",
    "\n",
    "print(f\"Kvasir -> {len(image_paths1)} images, {len(mask_paths1)} masks\")\n",
    "\n",
    "image_paths2 = sorted(glob(os.path.join(IMAGE_DIR2, \"*.png\")))\n",
    "mask_paths2  = sorted(glob(os.path.join(MASK_DIR2, \"*.png\")))\n",
    "\n",
    "print(f\"CVC -> {len(image_paths2)} images, {len(mask_paths2)} masks\")\n",
    "\n",
    "image_paths3 = sorted(glob(os.path.join(IMAGE_DIR3, \"*.png\")))\n",
    "mask_paths3  = sorted(glob(os.path.join(MASK_DIR3, \"*.png\")))\n",
    "\n",
    "print(f\"MPSD -> {len(image_paths3)} images, {len(mask_paths3)} masks\")\n",
    "\n",
    "image_paths = image_paths1+image_paths2+image_paths3\n",
    "mask_paths = mask_paths1 + mask_paths2 + mask_paths3\n",
    "image_names = [os.path.basename(p) for p in image_paths]\n",
    "mask_names = [os.path.basename(p) for p in mask_paths]\n",
    "assert image_names == mask_names, \"Image-mask filenames do not match!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61903c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T06:13:48.173379Z",
     "iopub.status.busy": "2025-08-28T06:13:48.173169Z",
     "iopub.status.idle": "2025-08-28T06:17:57.209994Z",
     "shell.execute_reply": "2025-08-28T06:17:57.209096Z"
    },
    "papermill": {
     "duration": 249.045313,
     "end_time": "2025-08-28T06:17:57.211522",
     "exception": false,
     "start_time": "2025-08-28T06:13:48.166209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_info = []\n",
    "\n",
    "def process_dataset(image_paths, mask_paths, dataset_name):\n",
    "    for img_path, mask_path in tqdm(zip(image_paths, mask_paths), total=len(image_paths), desc=f\"Processing {dataset_name}\"):\n",
    "        img = Image.open(img_path)\n",
    "        mask = Image.open(mask_path)\n",
    "        \n",
    "        \n",
    "        img_np = np.array(img)\n",
    "        mask_np = np.array(mask)\n",
    "        \n",
    "        \n",
    "        h, w = img_np.shape[:2]\n",
    "        \n",
    "        \n",
    "        mask_bin = (mask_np > 0).astype(np.uint8)\n",
    "        coverage_ratio = mask_bin.sum() / (h * w)\n",
    "        \n",
    "        data_info.append({\n",
    "            \"filename\": os.path.basename(img_path),\n",
    "            \"image_path\": img_path,\n",
    "            \"mask_path\": mask_path,\n",
    "            \"dataset\": dataset_name,\n",
    "            \"width\": w,\n",
    "            \"height\": h,\n",
    "            \"aspect_ratio\": w / h,\n",
    "            \"mask_coverage\": coverage_ratio\n",
    "        })\n",
    "\n",
    "\n",
    "\n",
    "process_dataset(image_paths1, mask_paths1, \"kvasir\")\n",
    "process_dataset(image_paths2, mask_paths2, \"cvc\")\n",
    "process_dataset(image_paths3, mask_paths3, \"mpsd\")\n",
    "\n",
    "df = pd.DataFrame(data_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8813e7ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T06:17:57.398873Z",
     "iopub.status.busy": "2025-08-28T06:17:57.398200Z",
     "iopub.status.idle": "2025-08-28T06:17:57.428715Z",
     "shell.execute_reply": "2025-08-28T06:17:57.427794Z"
    },
    "papermill": {
     "duration": 0.124849,
     "end_time": "2025-08-28T06:17:57.429967",
     "exception": false,
     "start_time": "2025-08-28T06:17:57.305118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n=== Dataset Summary ===\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbfcc12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T06:17:57.615964Z",
     "iopub.status.busy": "2025-08-28T06:17:57.615566Z",
     "iopub.status.idle": "2025-08-28T06:17:58.025430Z",
     "shell.execute_reply": "2025-08-28T06:17:58.024652Z"
    },
    "papermill": {
     "duration": 0.504089,
     "end_time": "2025-08-28T06:17:58.026859",
     "exception": false,
     "start_time": "2025-08-28T06:17:57.522770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.histplot(df[\"width\"], bins=20, kde=False)\n",
    "plt.title(\"Image Width Distribution\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.histplot(df[\"height\"], bins=20, kde=False)\n",
    "plt.title(\"Image Height Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3f14e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T06:17:58.226763Z",
     "iopub.status.busy": "2025-08-28T06:17:58.226455Z",
     "iopub.status.idle": "2025-08-28T06:17:58.597598Z",
     "shell.execute_reply": "2025-08-28T06:17:58.596905Z"
    },
    "papermill": {
     "duration": 0.470989,
     "end_time": "2025-08-28T06:17:58.599044",
     "exception": false,
     "start_time": "2025-08-28T06:17:58.128055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(df[\"aspect_ratio\"], bins=20, kde=True)\n",
    "plt.title(\"Aspect Ratio Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433d37d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T06:17:58.791799Z",
     "iopub.status.busy": "2025-08-28T06:17:58.791504Z",
     "iopub.status.idle": "2025-08-28T06:17:59.022479Z",
     "shell.execute_reply": "2025-08-28T06:17:59.021644Z"
    },
    "papermill": {
     "duration": 0.32663,
     "end_time": "2025-08-28T06:17:59.023857",
     "exception": false,
     "start_time": "2025-08-28T06:17:58.697227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.scatterplot(data=df, x=\"width\", y=\"height\", alpha=0.6)\n",
    "plt.title(\"Image Resolution Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7137300",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T06:17:59.229676Z",
     "iopub.status.busy": "2025-08-28T06:17:59.229104Z",
     "iopub.status.idle": "2025-08-28T06:17:59.597752Z",
     "shell.execute_reply": "2025-08-28T06:17:59.596992Z"
    },
    "papermill": {
     "duration": 0.473102,
     "end_time": "2025-08-28T06:17:59.598996",
     "exception": false,
     "start_time": "2025-08-28T06:17:59.125894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(df[\"mask_coverage\"], bins=30, kde=True)\n",
    "plt.axvline(df[\"mask_coverage\"].mean(), color='r', linestyle='--', label=\"Mean\")\n",
    "plt.legend()\n",
    "plt.title(\"Distribution of Polyp Coverage\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10e5f4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T06:17:59.795427Z",
     "iopub.status.busy": "2025-08-28T06:17:59.794922Z",
     "iopub.status.idle": "2025-08-28T06:17:59.897204Z",
     "shell.execute_reply": "2025-08-28T06:17:59.896500Z"
    },
    "papermill": {
     "duration": 0.201745,
     "end_time": "2025-08-28T06:17:59.898351",
     "exception": false,
     "start_time": "2025-08-28T06:17:59.696606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.boxplot(x=df[\"mask_coverage\"])\n",
    "plt.title(\"Boxplot of Polyp Coverage Ratio\")\n",
    "plt.xlabel(\"Mask coverage ratio\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a6252a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T06:18:00.154733Z",
     "iopub.status.busy": "2025-08-28T06:18:00.154484Z",
     "iopub.status.idle": "2025-08-28T06:18:00.160670Z",
     "shell.execute_reply": "2025-08-28T06:18:00.159845Z"
    },
    "papermill": {
     "duration": 0.10726,
     "end_time": "2025-08-28T06:18:00.162022",
     "exception": false,
     "start_time": "2025-08-28T06:18:00.054762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "empty_count = (df[\"mask_coverage\"] <= 0.005).sum()\n",
    "non_empty_count = (df[\"mask_coverage\"] > 0.005).sum()\n",
    "\n",
    "print(f\"Empty masks: {empty_count} ({empty_count/len(df)*100:.2f}%)\")\n",
    "print(f\"Non-empty masks: {non_empty_count} ({non_empty_count/len(df)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9f56dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T06:18:00.365520Z",
     "iopub.status.busy": "2025-08-28T06:18:00.364919Z",
     "iopub.status.idle": "2025-08-28T06:18:01.501214Z",
     "shell.execute_reply": "2025-08-28T06:18:01.500376Z"
    },
    "papermill": {
     "duration": 1.241658,
     "end_time": "2025-08-28T06:18:01.502588",
     "exception": false,
     "start_time": "2025-08-28T06:18:00.260930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_imgs = np.random.choice(image_paths, size=100, replace=False)\n",
    "pixels = []\n",
    "for p in sample_imgs:\n",
    "    img = cv2.imread(p)  # BGR\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    pixels.append(img_rgb.reshape(-1, 3))\n",
    "pixels = np.vstack(pixels)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.hist(pixels[:,0], bins=50, color='r', alpha=0.5, label='Red')\n",
    "plt.hist(pixels[:,1], bins=50, color='g', alpha=0.5, label='Green')\n",
    "plt.hist(pixels[:,2], bins=50, color='b', alpha=0.5, label='Blue')\n",
    "plt.title(\"Pixel Intensity Distribution (RGB channels)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcc21c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T06:18:01.705607Z",
     "iopub.status.busy": "2025-08-28T06:18:01.705355Z",
     "iopub.status.idle": "2025-08-28T06:18:02.681603Z",
     "shell.execute_reply": "2025-08-28T06:18:02.680758Z"
    },
    "papermill": {
     "duration": 1.079459,
     "end_time": "2025-08-28T06:18:02.682891",
     "exception": false,
     "start_time": "2025-08-28T06:18:01.603432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "means, stds = [], []\n",
    "for img_path in np.random.choice(image_paths, 200, replace=False):\n",
    "    img = np.array(Image.open(img_path)) / 255.0\n",
    "    means.append(img.mean())\n",
    "    stds.append(img.std())\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.scatterplot(x=means, y=stds)\n",
    "plt.xlabel(\"Mean Intensity\")\n",
    "plt.ylabel(\"Std Dev Intensity\")\n",
    "plt.title(\"Image Brightness vs Contrast\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1a7366",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T06:18:02.885145Z",
     "iopub.status.busy": "2025-08-28T06:18:02.884887Z",
     "iopub.status.idle": "2025-08-28T06:18:03.009026Z",
     "shell.execute_reply": "2025-08-28T06:18:03.008024Z"
    },
    "papermill": {
     "duration": 0.227297,
     "end_time": "2025-08-28T06:18:03.010299",
     "exception": false,
     "start_time": "2025-08-28T06:18:02.783002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_values = []\n",
    "for mask_path in np.random.choice(mask_paths, size=50, replace=False):\n",
    "    mask = np.array(Image.open(mask_path))\n",
    "    unique_vals = np.unique(mask)\n",
    "    mask_values.extend(unique_vals.tolist())\n",
    "\n",
    "mask_values = np.unique(mask_values)\n",
    "print(\"\\nUnique pixel values in masks:\", mask_values)\n",
    "if np.array_equal(mask_values, [0, 255]) or np.array_equal(mask_values, [0,1]):\n",
    "    print(\"✅ Masks are binary.\")\n",
    "else:\n",
    "    print(\"⚠️ Masks have unexpected values!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834a838b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T06:18:03.215958Z",
     "iopub.status.busy": "2025-08-28T06:18:03.215666Z",
     "iopub.status.idle": "2025-08-28T06:18:03.429808Z",
     "shell.execute_reply": "2025-08-28T06:18:03.429179Z"
    },
    "papermill": {
     "duration": 0.315936,
     "end_time": "2025-08-28T06:18:03.431448",
     "exception": false,
     "start_time": "2025-08-28T06:18:03.115512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.scatterplot(data=df, x=\"width\", y=\"mask_coverage\", alpha=0.7)\n",
    "plt.title(\"Mask Coverage vs Image Width\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfa4e61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T06:18:03.633351Z",
     "iopub.status.busy": "2025-08-28T06:18:03.633090Z",
     "iopub.status.idle": "2025-08-28T06:18:04.839372Z",
     "shell.execute_reply": "2025-08-28T06:18:04.838550Z"
    },
    "papermill": {
     "duration": 1.33072,
     "end_time": "2025-08-28T06:18:04.863373",
     "exception": false,
     "start_time": "2025-08-28T06:18:03.532653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_samples(num_samples=5):\n",
    "    samples = np.random.choice(len(image_paths), size=num_samples, replace=False)\n",
    "    plt.figure(figsize=(15, num_samples*3))\n",
    "    for i, idx in enumerate(samples):\n",
    "        img = Image.open(image_paths[idx])\n",
    "        mask = Image.open(mask_paths[idx])\n",
    "        \n",
    "        plt.subplot(num_samples, 2, 2*i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"Image: {os.path.basename(image_paths[idx])}\")\n",
    "        \n",
    "        plt.subplot(num_samples, 2, 2*i + 2)\n",
    "        plt.imshow(img)\n",
    "        plt.imshow(mask, cmap='Reds', alpha=0.5)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"Overlay Mask\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_samples(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739bae4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T06:18:05.128533Z",
     "iopub.status.busy": "2025-08-28T06:18:05.127816Z",
     "iopub.status.idle": "2025-08-28T06:18:06.808120Z",
     "shell.execute_reply": "2025-08-28T06:18:06.807309Z"
    },
    "papermill": {
     "duration": 1.833709,
     "end_time": "2025-08-28T06:18:06.824286",
     "exception": false,
     "start_time": "2025-08-28T06:18:04.990577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_image_and_mask(row):\n",
    "    img = cv2.imread(row[\"image_path\"])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    mask = cv2.imread(row[\"mask_path\"], cv2.IMREAD_GRAYSCALE)\n",
    "    return img, mask\n",
    "\n",
    "bins = pd.qcut(df[\"mask_coverage\"], q=4, labels=[\"small\", \"medium\", \"large\", 'huge'])\n",
    "sample_idx = df.groupby(bins).apply(lambda x: x.sample(3, random_state=1)).index.get_level_values(1)\n",
    "\n",
    "fig, axes = plt.subplots(4, 3, figsize=(12, 12))\n",
    "for i, idx in enumerate(sample_idx):\n",
    "    img, mask = load_image_and_mask(df.iloc[idx])\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    ax.imshow(img)\n",
    "    ax.imshow(mask, cmap=\"Reds\", alpha=0.4)\n",
    "    ax.set_title(f\"{bins.iloc[idx]} ({df['mask_coverage'].iloc[idx]:.2%})\")\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5927e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T06:18:07.156288Z",
     "iopub.status.busy": "2025-08-28T06:18:07.155498Z",
     "iopub.status.idle": "2025-08-28T06:18:07.590184Z",
     "shell.execute_reply": "2025-08-28T06:18:07.589392Z"
    },
    "papermill": {
     "duration": 0.581532,
     "end_time": "2025-08-28T06:18:07.596458",
     "exception": false,
     "start_time": "2025-08-28T06:18:07.014926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "row = df[df['dataset']=='kvasir'].sample(1, random_state=0).iloc[0]\n",
    "img = np.array(Image.open(row[\"image_path\"]).convert(\"RGB\"))\n",
    "mask = np.array(Image.open(row[\"mask_path\"]).convert(\"L\"))\n",
    "\n",
    "\n",
    "ys, xs = np.where(mask > 0)\n",
    "if len(xs) > 0 and len(ys) > 0:\n",
    "\n",
    "    x_min, x_max = xs.min(), xs.max()\n",
    "    y_min, y_max = ys.min(), ys.max()\n",
    "    \n",
    "\n",
    "    pad = 10\n",
    "    x_min, x_max = max(0, x_min-pad), min(img.shape[1], x_max+pad)\n",
    "    y_min, y_max = max(0, y_min-pad), min(img.shape[0], y_max+pad)\n",
    "    \n",
    "    masked_crop = img[y_min:y_max, x_min:x_max]\n",
    "else:\n",
    " \n",
    "    masked_crop = img\n",
    "\n",
    "# plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax1.imshow(masked_crop)\n",
    "ax1.set_title(\"Zoomed Polyp Region\")\n",
    "ax1.axis(\"off\")\n",
    "\n",
    "ax2.imshow(img)\n",
    "ax2.imshow(mask, cmap=\"Reds\", alpha=0.4)\n",
    "ax2.set_title(\"Full Image with Mask Overlay\")\n",
    "ax2.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea79c489",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T06:18:07.892671Z",
     "iopub.status.busy": "2025-08-28T06:18:07.892395Z",
     "iopub.status.idle": "2025-08-28T06:18:09.745555Z",
     "shell.execute_reply": "2025-08-28T06:18:09.744861Z"
    },
    "papermill": {
     "duration": 2.012829,
     "end_time": "2025-08-28T06:18:09.762132",
     "exception": false,
     "start_time": "2025-08-28T06:18:07.749303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_size = 5\n",
    "fig, axes = plt.subplots(grid_size, grid_size, figsize=(10,10))\n",
    "imgs = df.sample(n=grid_size**2, random_state=0)\n",
    "for ax, (_, row) in zip(axes.flatten(), imgs.iterrows()):\n",
    "    img = np.array(Image.open(row['image_path'])).astype(float)/255\n",
    "    mean, std = img.mean(), img.std()\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f\"μ={mean:.2f}, σ={std:.2f}\", fontsize=8)\n",
    "    ax.axis('off')\n",
    "plt.suptitle(\"Intensity Fingerprints\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd43081",
   "metadata": {
    "papermill": {
     "duration": 0.163322,
     "end_time": "2025-08-28T06:18:10.088621",
     "exception": false,
     "start_time": "2025-08-28T06:18:09.925299",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## hypo testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96933dfa",
   "metadata": {
    "papermill": {
     "duration": 0.173548,
     "end_time": "2025-08-28T06:18:10.418829",
     "exception": false,
     "start_time": "2025-08-28T06:18:10.245281",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Kolmogorov–Smirnov Test: Are polyp sizes uniformly distributed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7b6838",
   "metadata": {
    "papermill": {
     "duration": 0.156457,
     "end_time": "2025-08-28T06:18:10.728240",
     "exception": false,
     "start_time": "2025-08-28T06:18:10.571783",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Purpose\n",
    "\n",
    "We want to understand whether polyp sizes in the dataset follow a normal distribution. This is important because many statistical methods assume normality, and model strategies (like data augmentation or stratified sampling) may depend on the distribution of polyp sizes. In medical imaging, datasets often have a skew toward small lesions, which can affect model performance.\n",
    "\n",
    "#### Hypotheses\n",
    "\n",
    "H₀ (null): Polyp coverage follows a normal distribution.\n",
    "\n",
    "H₁ (alternative): Polyp coverage does not follow a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e43cfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T06:18:11.045303Z",
     "iopub.status.busy": "2025-08-28T06:18:11.044445Z",
     "iopub.status.idle": "2025-08-28T06:18:11.051967Z",
     "shell.execute_reply": "2025-08-28T06:18:11.051071Z"
    },
    "papermill": {
     "duration": 0.168261,
     "end_time": "2025-08-28T06:18:11.053379",
     "exception": false,
     "start_time": "2025-08-28T06:18:10.885118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "stat, p = shapiro(df[\"mask_coverage\"])\n",
    "\n",
    "print(f\"KS test (coverage vs uniform): {p:.3e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4245265c",
   "metadata": {
    "papermill": {
     "duration": 0.151381,
     "end_time": "2025-08-28T06:18:11.357915",
     "exception": false,
     "start_time": "2025-08-28T06:18:11.206534",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Polyp coverage does not follow a normal distribution. The data is strongly skewed, with most polyps being small and a few large ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43aae45",
   "metadata": {
    "papermill": {
     "duration": 0.152938,
     "end_time": "2025-08-28T06:18:11.663547",
     "exception": false,
     "start_time": "2025-08-28T06:18:11.510609",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Spearman Correlation: Do larger images tend to have larger polyps?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaf24ba",
   "metadata": {
    "papermill": {
     "duration": 0.239881,
     "end_time": "2025-08-28T06:18:12.056316",
     "exception": false,
     "start_time": "2025-08-28T06:18:11.816435",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Purpose:\n",
    "Since datasets often contain images from different cameras or settings, larger image resolutions might be associated with larger polyps. Understanding this helps us know if resolution introduces bias in polyp size distribution.\n",
    "\n",
    "#### Hypotheses:\n",
    "\n",
    "H₀: There is no monotonic relationship between image resolution (width × height) and polyp size (coverage).\n",
    "\n",
    "H₁: There is a monotonic relationship between resolution and polyp size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a33f42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T06:18:12.411465Z",
     "iopub.status.busy": "2025-08-28T06:18:12.411186Z",
     "iopub.status.idle": "2025-08-28T06:18:12.424856Z",
     "shell.execute_reply": "2025-08-28T06:18:12.424092Z"
    },
    "papermill": {
     "duration": 0.179633,
     "end_time": "2025-08-28T06:18:12.426012",
     "exception": false,
     "start_time": "2025-08-28T06:18:12.246379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "corr, p = spearmanr(df[\"width\"]*df[\"height\"], df[\"mask_coverage\"])\n",
    "print(f\"Spearman correlation (Resolution vs Coverage): {corr:.3f}, p={p:.3e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34b87dd",
   "metadata": {
    "papermill": {
     "duration": 0.157205,
     "end_time": "2025-08-28T06:18:12.748624",
     "exception": false,
     "start_time": "2025-08-28T06:18:12.591419",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There is a weak but significant positive correlation: larger-resolution images tend to have slightly larger polyps.\n",
    "This is not a strong biological effect but may indicate that some datasets (with higher resolution) contain larger lesions. For model building, this could create dataset bias where resolution and lesion size are confounded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea7f9ab",
   "metadata": {
    "papermill": {
     "duration": 0.15706,
     "end_time": "2025-08-28T06:18:13.063916",
     "exception": false,
     "start_time": "2025-08-28T06:18:12.906856",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### T-test: Do portrait vs. landscape images differ in polyp coverage?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cde11e",
   "metadata": {
    "papermill": {
     "duration": 0.151418,
     "end_time": "2025-08-28T06:18:13.366700",
     "exception": false,
     "start_time": "2025-08-28T06:18:13.215282",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Purpose:\n",
    "Images come in both portrait and landscape orientations. If orientation influences polyp coverage, it may point to differences in how images were captured or cropped (scanner/device bias).\n",
    "\n",
    "#### Hypotheses:\n",
    "\n",
    "H₀: Mean polyp coverage is the same in portrait and landscape images.\n",
    "\n",
    "H₁: Mean polyp coverage is different between portrait and landscape images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436d3d98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T06:18:13.675001Z",
     "iopub.status.busy": "2025-08-28T06:18:13.674712Z",
     "iopub.status.idle": "2025-08-28T06:18:13.690135Z",
     "shell.execute_reply": "2025-08-28T06:18:13.689323Z"
    },
    "papermill": {
     "duration": 0.172449,
     "end_time": "2025-08-28T06:18:13.691337",
     "exception": false,
     "start_time": "2025-08-28T06:18:13.518888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "portrait = df[df[\"aspect_ratio\"] < 1][\"mask_coverage\"]\n",
    "landscape = df[df[\"aspect_ratio\"] >= 1][\"mask_coverage\"]\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "t_stat, p_val = ttest_ind(portrait, landscape, equal_var=False)\n",
    "print(f\"T-test (portrait vs landscape) p={p_val:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cbd34d",
   "metadata": {
    "papermill": {
     "duration": 0.153459,
     "end_time": "2025-08-28T06:18:13.998613",
     "exception": false,
     "start_time": "2025-08-28T06:18:13.845154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There is a statistically significant difference in polyp coverage between portrait and landscape images. The difference is small but suggests that orientation may introduce bias. For training, mixing orientations without balancing could lead to subtle model biases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e9f625",
   "metadata": {
    "papermill": {
     "duration": 0.15155,
     "end_time": "2025-08-28T06:18:14.300829",
     "exception": false,
     "start_time": "2025-08-28T06:18:14.149279",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Pearson Correlation: Is polyp size related to image contrast?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3d9b68",
   "metadata": {
    "papermill": {
     "duration": 0.153117,
     "end_time": "2025-08-28T06:18:14.660424",
     "exception": false,
     "start_time": "2025-08-28T06:18:14.507307",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Purpose:\n",
    "Image contrast (measured by pixel intensity standard deviation) affects model learning. We want to know whether larger polyps also tend to have higher/lower contrast, which could affect segmentation difficulty.\n",
    "\n",
    "#### Hypotheses:\n",
    "\n",
    "H₀: There is no linear relationship between polyp size and image contrast.\n",
    "\n",
    "H₁: There is a linear relationship between polyp size and image contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d184501",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T06:18:14.970276Z",
     "iopub.status.busy": "2025-08-28T06:18:14.969997Z",
     "iopub.status.idle": "2025-08-28T06:19:38.336224Z",
     "shell.execute_reply": "2025-08-28T06:19:38.335413Z"
    },
    "papermill": {
     "duration": 83.690249,
     "end_time": "2025-08-28T06:19:38.503554",
     "exception": false,
     "start_time": "2025-08-28T06:18:14.813305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "stds = []\n",
    "for img_path in image_paths:\n",
    "    img = np.array(Image.open(img_path)) / 255.0\n",
    "    stds.append(img.std())\n",
    "df[\"intensity_std\"] = stds\n",
    "\n",
    "corr, p = pearsonr(df[\"mask_coverage\"], df[\"intensity_std\"])\n",
    "print(f\"Correlation (mask coverage vs contrast): {corr:.3f}, p={p:.3e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876eb2c8",
   "metadata": {
    "papermill": {
     "duration": 0.153679,
     "end_time": "2025-08-28T06:19:38.809580",
     "exception": false,
     "start_time": "2025-08-28T06:19:38.655901",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There is a very weak but statistically significant positive correlation: larger polyps tend to have slightly higher contrast. This could mean that bigger lesions have more visible texture variation, but the effect is small. From a modeling perspective, this correlation is unlikely to provide strong predictive power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72ced4a",
   "metadata": {
    "papermill": {
     "duration": 0.150216,
     "end_time": "2025-08-28T06:19:39.112493",
     "exception": false,
     "start_time": "2025-08-28T06:19:38.962277",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprosessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0edeb06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T06:19:39.419493Z",
     "iopub.status.busy": "2025-08-28T06:19:39.419206Z",
     "iopub.status.idle": "2025-08-28T06:19:44.777654Z",
     "shell.execute_reply": "2025-08-28T06:19:44.777063Z"
    },
    "papermill": {
     "duration": 5.512307,
     "end_time": "2025-08-28T06:19:44.779082",
     "exception": false,
     "start_time": "2025-08-28T06:19:39.266775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e8c210",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T06:19:45.086886Z",
     "iopub.status.busy": "2025-08-28T06:19:45.086381Z",
     "iopub.status.idle": "2025-08-28T06:19:45.096272Z",
     "shell.execute_reply": "2025-08-28T06:19:45.095516Z"
    },
    "papermill": {
     "duration": 0.163465,
     "end_time": "2025-08-28T06:19:45.097451",
     "exception": false,
     "start_time": "2025-08-28T06:19:44.933986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PolypDataset(Dataset):\n",
    "    def __init__(self, datasets, transform=None, exts=(\"png\",\"jpg\",\"jpeg\")):\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.mask_paths = []\n",
    "\n",
    "        for image_dir, mask_dir in datasets:\n",
    "            image_paths, mask_paths = self._load_dataset(image_dir, mask_dir, exts)\n",
    "            self.image_paths.extend(image_paths)\n",
    "            self.mask_paths.extend(mask_paths)\n",
    "\n",
    "    def _load_dataset(self, image_dir, mask_dir, exts):\n",
    "        \n",
    "        image_paths = []\n",
    "        for ext in exts:\n",
    "            image_paths.extend(glob(os.path.join(image_dir, f\"*.{ext}\")))\n",
    "        image_paths = sorted(image_paths)\n",
    "\n",
    "        \n",
    "        mask_paths = []\n",
    "        for ext in exts:\n",
    "            mask_paths.extend(glob(os.path.join(mask_dir, f\"*.{ext}\")))\n",
    "        mask_paths = sorted(mask_paths)\n",
    "\n",
    "        \n",
    "        image_names = [os.path.basename(p) for p in image_paths]\n",
    "        mask_dict = {os.path.basename(p): p for p in mask_paths}\n",
    "        matched = [(img, mask_dict[os.path.basename(img)]) for img in image_paths if os.path.basename(img) in mask_dict]\n",
    "\n",
    "        if matched:\n",
    "            imgs, masks = zip(*matched)\n",
    "        else:\n",
    "            imgs, masks = [], []\n",
    "\n",
    "        return list(imgs), list(masks)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def pad_to_square(self, img, color=(0, 0, 0)):\n",
    "        h, w = img.shape[:2]\n",
    "        size = max(h, w)\n",
    "        top = (size - h) // 2\n",
    "        bottom = size - h - top\n",
    "        left = (size - w) // 2\n",
    "        right = size - w - left\n",
    "        return cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image = cv2.imread(self.image_paths[idx])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(self.mask_paths[idx], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        \n",
    "        image = self.pad_to_square(image)\n",
    "        mask = self.pad_to_square(mask, color=(0,))\n",
    "\n",
    "        \n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image, mask = augmented[\"image\"], augmented[\"mask\"]\n",
    "\n",
    "        return image, mask.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4d90b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T06:19:45.406294Z",
     "iopub.status.busy": "2025-08-28T06:19:45.406010Z",
     "iopub.status.idle": "2025-08-28T06:19:45.418833Z",
     "shell.execute_reply": "2025-08-28T06:19:45.417903Z"
    },
    "papermill": {
     "duration": 0.168698,
     "end_time": "2025-08-28T06:19:45.419989",
     "exception": false,
     "start_time": "2025-08-28T06:19:45.251291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.2),\n",
    "    A.RandomRotate90(p=0.2),\n",
    "    A.ShiftScaleRotate(\n",
    "        shift_limit=0.05, scale_limit=0.1, rotate_limit=15, \n",
    "        p=0.5, border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0\n",
    "    ),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=15, val_shift_limit=10, p=0.3),\n",
    "    A.GaussianBlur(p=0.2),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87406f04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T06:19:45.785589Z",
     "iopub.status.busy": "2025-08-28T06:19:45.785294Z",
     "iopub.status.idle": "2025-08-28T06:19:46.356734Z",
     "shell.execute_reply": "2025-08-28T06:19:46.355818Z"
    },
    "papermill": {
     "duration": 0.784361,
     "end_time": "2025-08-28T06:19:46.358597",
     "exception": false,
     "start_time": "2025-08-28T06:19:45.574236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "datasets = [\n",
    "    (\"/kaggle/input/kvasirseg/Kvasir-SEG/Kvasir-SEG/images\",\n",
    "     \"/kaggle/input/kvasirseg/Kvasir-SEG/Kvasir-SEG/masks\"),\n",
    "\n",
    "    (\"/kaggle/input/cvcclinicdb/PNG/Original\",\n",
    "     \"/kaggle/input/cvcclinicdb/PNG/Ground Truth\"),\n",
    "\n",
    "    (\"/kaggle/input/merged-polyp-segmentation-datasets/images_valid/images_valid\",\n",
    "     \"/kaggle/input/merged-polyp-segmentation-datasets/images_valid/masks_valid\"),\n",
    "]\n",
    "\n",
    "full_dataset = PolypDataset(datasets, transform=None)\n",
    "\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "\n",
    "train_dataset.dataset.transform = train_transform  \n",
    "val_dataset.dataset.transform = val_transform     \n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=4)\n",
    "\n",
    "\n",
    "for images, masks in train_loader:\n",
    "    print(images.shape)  # (B, 3, 512, 512)\n",
    "    print(masks.shape)   # (B, 512, 512)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2139e5ce",
   "metadata": {
    "papermill": {
     "duration": 0.15308,
     "end_time": "2025-08-28T06:19:46.712189",
     "exception": false,
     "start_time": "2025-08-28T06:19:46.559109",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# train baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43141228",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T06:19:47.019100Z",
     "iopub.status.busy": "2025-08-28T06:19:47.018783Z",
     "iopub.status.idle": "2025-08-28T06:19:52.508778Z",
     "shell.execute_reply": "2025-08-28T06:19:52.507969Z"
    },
    "papermill": {
     "duration": 5.64583,
     "end_time": "2025-08-28T06:19:52.510363",
     "exception": false,
     "start_time": "2025-08-28T06:19:46.864533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResUNet(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(ResUNet, self).__init__()\n",
    "        base_model = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n",
    "        base_layers = list(base_model.children())\n",
    "\n",
    "        self.layer0 = nn.Sequential(*base_layers[:3])  \n",
    "        self.layer1 = nn.Sequential(*base_layers[3:5]) \n",
    "        self.layer2 = base_layers[5]                    \n",
    "        self.layer3 = base_layers[6]                   \n",
    "        self.layer4 = base_layers[7]                   \n",
    "\n",
    "        self.upsample4 = self._upsample(512, 256)    \n",
    "        self.upsample3 = self._upsample(256, 128)     \n",
    "        self.upsample2 = self._upsample(128, 64)      \n",
    "        self.upsample1 = self._upsample(64, 64)       \n",
    "\n",
    "        \n",
    "        self.upsample0 = self._upsample(64, 64)        \n",
    "\n",
    "        self.final_conv = nn.Conv2d(64, n_classes, kernel_size=1)\n",
    "\n",
    "    def _upsample(self, in_ch, out_ch):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_ch, out_ch, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.layer0(x)  \n",
    "        x1 = self.layer1(x0) \n",
    "        x2 = self.layer2(x1) \n",
    "        x3 = self.layer3(x2) \n",
    "        x4 = self.layer4(x3) \n",
    "\n",
    "        x = self.upsample4(x4) + x3  \n",
    "        x = self.upsample3(x) + x2  \n",
    "        x = self.upsample2(x) + x1  \n",
    "        x = self.upsample1(x) + x0  \n",
    "        x = self.upsample0(x)       \n",
    "\n",
    "        return self.final_conv(x)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7a803f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T06:19:52.819199Z",
     "iopub.status.busy": "2025-08-28T06:19:52.818174Z",
     "iopub.status.idle": "2025-08-28T06:19:52.825094Z",
     "shell.execute_reply": "2025-08-28T06:19:52.824496Z"
    },
    "papermill": {
     "duration": 0.162667,
     "end_time": "2025-08-28T06:19:52.826233",
     "exception": false,
     "start_time": "2025-08-28T06:19:52.663566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dice_loss_from_logits_1c(logits, target, eps=1e-6):\n",
    "    \n",
    "    prob = torch.sigmoid(logits)\n",
    "    inter = (prob*target).sum(dim=(1,2,3))\n",
    "    den   = prob.sum(dim=(1,2,3)) + target.sum(dim=(1,2,3))\n",
    "    return 1 - ((2*inter + eps) / (den + eps)).mean()\n",
    "\n",
    "def dice_coeff(pred, target):\n",
    "    smooth = 1.\n",
    "    pred = torch.sigmoid(pred)\n",
    "    pred = (pred > 0.5).float()\n",
    "    target = target.float()\n",
    "    intersection = (pred * target).sum()\n",
    "    return (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)\n",
    "\n",
    "def iou_score(pred, target, threshold=0.5, smooth=1e-6):\n",
    "    pred = torch.sigmoid(pred) if pred.dim() == 4 else pred  # apply sigmoid if logits\n",
    "    pred = (pred > threshold).float()\n",
    "    target = target.float()\n",
    "    \n",
    "    intersection = (pred * target).sum(dim=[1,2])   # sum over spatial dims\n",
    "    union = pred.sum(dim=[1,2]) + target.sum(dim=[1,2]) - intersection\n",
    "    \n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "    return iou.mean().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0869f287",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T06:19:53.131367Z",
     "iopub.status.busy": "2025-08-28T06:19:53.131075Z",
     "iopub.status.idle": "2025-08-28T06:19:53.136782Z",
     "shell.execute_reply": "2025-08-28T06:19:53.136083Z"
    },
    "papermill": {
     "duration": 0.16065,
     "end_time": "2025-08-28T06:19:53.138011",
     "exception": false,
     "start_time": "2025-08-28T06:19:52.977361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_res(train_losses,val_losses,val_dice,val_iou):\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(10, 15))\n",
    "    \n",
    "    # --- Loss ---\n",
    "    axes[0].plot(train_losses, label=\"Train Loss\")\n",
    "    axes[0].plot(val_losses, label=\"Val Loss\")\n",
    "    axes[0].set_xlabel(\"Epoch\")\n",
    "    axes[0].set_ylabel(\"Loss\")\n",
    "    axes[0].legend()\n",
    "    axes[0].set_title(\"Learning Curve - Loss\")\n",
    "    \n",
    "    # --- Dice ---\n",
    "    axes[1].plot(val_dice, label=\"Val Dice\")\n",
    "    axes[1].set_xlabel(\"Epoch\")\n",
    "    axes[1].set_ylabel(\"Dice Coefficient\")\n",
    "    axes[1].legend()\n",
    "    axes[1].set_title(\"Learning Curve - Dice Score\")\n",
    "    \n",
    "    # --- IOU ---\n",
    "    axes[2].plot(val_iou, label=\"Val IOU\")\n",
    "    axes[2].set_xlabel(\"Epoch\")\n",
    "    axes[2].set_ylabel(\"IOU metric\")\n",
    "    axes[2].legend()\n",
    "    axes[2].set_title(\"Learning Curve - IOU Score\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e0f0da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T06:19:53.449477Z",
     "iopub.status.busy": "2025-08-28T06:19:53.449157Z",
     "iopub.status.idle": "2025-08-28T07:13:29.351714Z",
     "shell.execute_reply": "2025-08-28T07:13:29.350587Z"
    },
    "papermill": {
     "duration": 3217.243348,
     "end_time": "2025-08-28T07:13:30.535425",
     "exception": false,
     "start_time": "2025-08-28T06:19:53.292077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ResUNet(n_classes=2).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "train_losses, val_losses, val_dice,val_iou = [], [], [],[]\n",
    "best_val_dice = 0.0\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, masks in tqdm(train_loader):\n",
    "        images = images.to(device)\n",
    "        \n",
    "        masks = (masks > 0).long().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)  \n",
    "        loss = F.cross_entropy(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss, dice,iou = 0, 0,0\n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            images = images.to(device)\n",
    "            masks = (masks > 0).long().to(device)\n",
    "            outputs = model(images)\n",
    "            loss = F.cross_entropy(outputs, masks)\n",
    "            val_loss += loss.item()\n",
    "            pred_logits = outputs[:, 1, :, :]\n",
    "            dice += dice_coeff(pred_logits, masks).item()\n",
    "            iou += iou_score(pred_logits, masks)\n",
    "\n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "    val_dice.append(dice / len(val_loader))\n",
    "    val_iou.append(iou/ len(val_loader))\n",
    "\n",
    "    if dice > best_val_dice:\n",
    "        best_val_dice = dice\n",
    "        torch.save(model.state_dict(), \"base_model.pth\")\n",
    "        print(\"✅ Saved best model!\")\n",
    "    \n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {train_losses[-1]:.4f} | Val Loss: {val_losses[-1]:.4f} | Dice: {val_dice[-1]:.4f} | IOU: {val_iou[-1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfb2d1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T07:13:32.915277Z",
     "iopub.status.busy": "2025-08-28T07:13:32.914972Z",
     "iopub.status.idle": "2025-08-28T07:13:33.481524Z",
     "shell.execute_reply": "2025-08-28T07:13:33.480693Z"
    },
    "papermill": {
     "duration": 1.756214,
     "end_time": "2025-08-28T07:13:33.483649",
     "exception": false,
     "start_time": "2025-08-28T07:13:31.727435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_res(train_losses,val_losses,val_dice,val_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320cc062",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T07:13:35.866653Z",
     "iopub.status.busy": "2025-08-28T07:13:35.866350Z",
     "iopub.status.idle": "2025-08-28T07:13:35.871678Z",
     "shell.execute_reply": "2025-08-28T07:13:35.870953Z"
    },
    "papermill": {
     "duration": 1.18871,
     "end_time": "2025-08-28T07:13:35.872915",
     "exception": false,
     "start_time": "2025-08-28T07:13:34.684205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_tta(model, x):\n",
    "    outs=[]\n",
    "    with torch.no_grad():\n",
    "        o = model(x)\n",
    "        outs.append(o)\n",
    "        o = model(torch.flip(x,[3]));        outs.append(torch.flip(o,[3]))\n",
    "        o = model(torch.flip(x,[2]));        outs.append(torch.flip(o,[2]))\n",
    "        o = model(x.transpose(2,3));         outs.append(model(x.transpose(2,3)).transpose(2,3))\n",
    "    return torch.stack(outs).mean(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d950b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T07:13:38.283885Z",
     "iopub.status.busy": "2025-08-28T07:13:38.283363Z",
     "iopub.status.idle": "2025-08-28T08:20:17.556540Z",
     "shell.execute_reply": "2025-08-28T08:20:17.555766Z"
    },
    "papermill": {
     "duration": 4000.389318,
     "end_time": "2025-08-28T08:20:17.557687",
     "exception": false,
     "start_time": "2025-08-28T07:13:37.168369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ResUNet(n_classes=1).to(device)\n",
    "train_losses, val_losses, val_dice,val_iou = [], [], [],[]\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=3, verbose=True\n",
    ")\n",
    "\n",
    "pos_w = torch.tensor([2.0], device=device) \n",
    "best_val_dice = 0.0\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, masks in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\"):\n",
    "        images = images.to(device)                                 \n",
    "        masks  = (masks > 0).float().unsqueeze(1).to(device)       \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images)                                    \n",
    "\n",
    "        bce  = F.binary_cross_entropy_with_logits(logits, masks, pos_weight=pos_w)\n",
    "        loss = bce + 0.5 * dice_loss_from_logits_1c(logits, masks)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "   \n",
    "    model.eval()\n",
    "    val_loss, dice, iou = 0.0, 0.0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\"):\n",
    "            images = images.to(device)\n",
    "            masks  = (masks > 0).float().unsqueeze(1).to(device)  \n",
    "\n",
    "            logits = predict_tta(model, images)\n",
    "\n",
    "            bce  = F.binary_cross_entropy_with_logits(logits, masks, pos_weight=pos_w)\n",
    "            loss = bce + 0.5 * dice_loss_from_logits_1c(logits, masks)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            dice += dice_coeff(logits, masks).item()\n",
    "            iou  += iou_score(logits, masks)\n",
    "\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    val_loss /= len(val_loader)\n",
    "    dice /= len(val_loader)\n",
    "    iou  /= len(val_loader)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    val_dice.append(dice)\n",
    "    val_iou.append(iou)\n",
    "\n",
    "   \n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    \n",
    "    if dice > best_val_dice:\n",
    "        best_val_dice = dice\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(\"✅ Saved best model!\")\n",
    "\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "          f\"Train {train_loss:.4f} | Val {val_loss:.4f} | \"\n",
    "          f\"Dice {dice:.4f} | IoU {iou:.4f} | LR {optimizer.param_groups[0]['lr']:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bd6ada",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T08:20:22.425214Z",
     "iopub.status.busy": "2025-08-28T08:20:22.424910Z",
     "iopub.status.idle": "2025-08-28T08:20:23.000987Z",
     "shell.execute_reply": "2025-08-28T08:20:23.000230Z"
    },
    "papermill": {
     "duration": 3.00909,
     "end_time": "2025-08-28T08:20:23.002813",
     "exception": false,
     "start_time": "2025-08-28T08:20:19.993723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_res(train_losses,val_losses,val_dice,val_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab09e82e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T08:20:28.081904Z",
     "iopub.status.busy": "2025-08-28T08:20:28.081063Z",
     "iopub.status.idle": "2025-08-28T08:20:29.965471Z",
     "shell.execute_reply": "2025-08-28T08:20:29.964688Z"
    },
    "papermill": {
     "duration": 4.385944,
     "end_time": "2025-08-28T08:20:29.967612",
     "exception": false,
     "start_time": "2025-08-28T08:20:25.581668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_samples(model, dataloader, device, num_samples=4, thr=0.5):\n",
    "    model.eval()\n",
    "    images, masks = next(iter(dataloader))  \n",
    "    images = images.to(device)\n",
    "    masks  = (masks > 0).float().to(device)  \n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)              \n",
    "\n",
    "        if outputs.shape[1] == 1: \n",
    "            probs = torch.sigmoid(outputs)\n",
    "            preds = (probs > thr).float()\n",
    "        else:                     \n",
    "            probs = torch.softmax(outputs, dim=1)[:,1:2]\n",
    "            preds = (probs > thr).float()\n",
    "\n",
    "    images = images.cpu().permute(0,2,3,1).numpy()\n",
    "    masks  = masks.cpu().squeeze().numpy()\n",
    "    preds  = preds.cpu().squeeze().numpy()\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        plt.figure(figsize=(12,4))\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.imshow((images[i]*0.229+0.485).clip(0,1)) \n",
    "        plt.title(\"Image\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.imshow(masks[i], cmap=\"gray\")\n",
    "        plt.title(\"Ground Truth\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.imshow(preds[i], cmap=\"gray\")\n",
    "        plt.title(\"Prediction\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "show_samples(model, val_loader, device, num_samples=5, thr=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac4a1a5",
   "metadata": {
    "papermill": {
     "duration": 2.462296,
     "end_time": "2025-08-28T08:20:35.016137",
     "exception": false,
     "start_time": "2025-08-28T08:20:32.553841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 930614,
     "sourceId": 1574219,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1316959,
     "sourceId": 7681479,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7325827,
     "sourceId": 11673222,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7620.589277,
   "end_time": "2025-08-28T08:20:40.767863",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-28T06:13:40.178586",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
